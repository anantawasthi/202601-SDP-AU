{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMs/D77EMrPrFztvKA4A57+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ae060d7a"},"source":["## **Data Splitting Strategies**\n","\n","Once the feature-engineered dataset is ready, a crucial step in building robust machine learning models is splitting the data into different sets. This process ensures that the model is evaluated on unseen data, providing a more reliable estimate of its generalization performance. This section will discuss various data splitting methods, their use cases, advantages, and disadvantages."]},{"cell_type":"markdown","metadata":{"id":"46d84ae9"},"source":["### **1. Simple Train/Test Split**\n","\n","This is the most basic and common method of splitting data. The dataset is divided into two parts: a training set (used to train the model) and a test set (used to evaluate the model's performance on unseen data)."]},{"cell_type":"markdown","metadata":{"id":"ccf00607"},"source":["**When to Use:**\n","*   When you have a very large dataset, and a simple split is sufficient to get a representative test set.\n","*   As a quick initial evaluation of a model.\n","\n","**Pros:**\n","*   Simple to implement and understand.\n","*   Fast to execute.\n","*   Provides a straightforward estimate of model performance on unseen data.\n","\n","**Cons:**\n","*   The performance estimate can be highly dependent on the particular split. If the split is not random or representative, the test set might not accurately reflect real-world data.\n","*   Information loss: The model is not trained on the entire dataset, potentially leading to a less robust model if the dataset is small."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9e8fc067","executionInfo":{"status":"ok","timestamp":1768162835367,"user_tz":-330,"elapsed":2185,"user":{"displayName":"Anant Prakash Awasthi","userId":"00676186995527977815"}},"outputId":"2f56c928-bc94-4282-a806-cd0725ebac6c"},"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","# Generate a dummy dataset\n","X = np.random.rand(100, 5) # 100 samples, 5 features\n","y = (X[:, 0] + X[:, 1] > 1).astype(int) # Binary target variable\n","\n","print(f\"Original dataset shape: X={X.shape}, y={y.shape}\")\n","\n","# Perform a simple train/test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","print(f\"\\nTrain set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n","print(f\"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original dataset shape: X=(100, 5), y=(100,)\n","\n","Train set shape: X_train=(70, 5), y_train=(70,)\n","Test set shape: X_test=(30, 5), y_test=(30,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"b73c0d6b"},"source":["### **2. K-Fold Cross-Validation**\n","\n","K-Fold Cross-Validation is a more robust method that divides the dataset into *k* equally sized folds. The model is then trained *k* times. In each iteration, one fold is used as the test set, and the remaining *k-1* folds are used as the training set. The final performance metric is the average of the *k* evaluation scores."]},{"cell_type":"markdown","metadata":{"id":"3fd7ef17"},"source":["**When to Use:**\n","*   When you want a more reliable estimate of your model's performance.\n","*   When the dataset is not extremely large, and you want to make the most of your data for training and evaluation.\n","*   To compare different models and select the best performing one.\n","\n","**Pros:**\n","*   Provides a more robust and less biased estimate of model performance compared to a single train/test split.\n","*   Every data point gets to be in a test set exactly once, and in a training set *k-1* times, maximizing data utilization.\n","*   Reduces variance in performance estimation.\n","\n","**Cons:**\n","*   Computationally more expensive than a simple train/test split because the model is trained *k* times.\n","*   Can be slow for very large datasets or complex models."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"17184e92","executionInfo":{"status":"ok","timestamp":1768162836216,"user_tz":-330,"elapsed":260,"user":{"displayName":"Anant Prakash Awasthi","userId":"00676186995527977815"}},"outputId":"cf04eabc-96fa-4e0c-e6a5-40149ef8275d"},"source":["from sklearn.model_selection import KFold\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# Initialize KFold cross-validator\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","model = LogisticRegression(random_state=42)\n","\n","accuracy_scores = []\n","\n","print(\"Performing K-Fold Cross-Validation (k=5):\")\n","for fold, (train_index, test_index) in enumerate(kf.split(X)):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    accuracy_scores.append(accuracy)\n","\n","    print(f\"  Fold {fold+1}: Accuracy = {accuracy:.4f}\")\n","\n","print(f\"\\nAverage Accuracy: {np.mean(accuracy_scores):.4f}\")\n","print(f\"Standard Deviation of Accuracy: {np.std(accuracy_scores):.4f}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing K-Fold Cross-Validation (k=5):\n","  Fold 1: Accuracy = 0.8000\n","  Fold 2: Accuracy = 0.9500\n","  Fold 3: Accuracy = 1.0000\n","  Fold 4: Accuracy = 0.9000\n","  Fold 5: Accuracy = 0.9500\n","\n","Average Accuracy: 0.9200\n","Standard Deviation of Accuracy: 0.0678\n"]}]},{"cell_type":"markdown","metadata":{"id":"53de2bc8"},"source":["### **3. Stratified K-Fold Cross-Validation**\n","\n","Stratified K-Fold Cross-Validation is a variation of K-Fold that ensures each fold has approximately the same percentage of samples for each target class as the complete set. This is particularly useful for classification problems with imbalanced datasets, where some classes are much rarer than others."]},{"cell_type":"markdown","metadata":{"id":"1a000d07"},"source":["**When to Use:**\n","*   Primarily for classification tasks, especially with imbalanced datasets.\n","*   To ensure that each fold is representative of the overall class distribution.\n","\n","**Pros:**\n","*   Maintains the proportion of target classes in each fold, leading to more reliable performance estimates for imbalanced datasets.\n","*   Reduces the risk of having folds with very few or no samples of a minority class.\n","\n","**Cons:**\n","*   Similar computational cost to standard K-Fold Cross-Validation.\n","*   Not directly applicable to regression problems (though stratification by quantiles could be considered)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"318f3fa6","executionInfo":{"status":"ok","timestamp":1768162836820,"user_tz":-330,"elapsed":64,"user":{"displayName":"Anant Prakash Awasthi","userId":"00676186995527977815"}},"outputId":"87f996c9-8245-44fd-90fa-4267ab14af6b"},"source":["from sklearn.model_selection import StratifiedKFold\n","\n","# Create an imbalanced dummy dataset\n","X_imb = np.random.rand(100, 5)\n","y_imb = np.array([0]*90 + [1]*10) # 90% class 0, 10% class 1\n","np.random.shuffle(y_imb) # Shuffle the labels\n","\n","print(f\"Original imbalanced dataset class distribution: {np.bincount(y_imb)}\")\n","\n","# Initialize Stratified KFold cross-validator\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","model_imb = LogisticRegression(random_state=42)\n","accuracy_scores_imb = []\n","\n","print(\"\\nPerforming Stratified K-Fold Cross-Validation (k=5) for imbalanced data:\")\n","for fold, (train_index, test_index) in enumerate(skf.split(X_imb, y_imb)):\n","    X_train, X_test = X_imb[train_index], X_imb[test_index]\n","    y_train, y_test = y_imb[train_index], y_imb[test_index]\n","\n","    # Check class distribution in each fold\n","    print(f\"  Fold {fold+1} train class distribution: {np.bincount(y_train)}\")\n","    print(f\"  Fold {fold+1} test class distribution: {np.bincount(y_test)}\")\n","\n","    model_imb.fit(X_train, y_train)\n","    y_pred = model_imb.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    accuracy_scores_imb.append(accuracy)\n","\n","    print(f\"  Fold {fold+1}: Accuracy = {accuracy:.4f}\")\n","\n","print(f\"\\nAverage Stratified Accuracy: {np.mean(accuracy_scores_imb):.4f}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original imbalanced dataset class distribution: [90 10]\n","\n","Performing Stratified K-Fold Cross-Validation (k=5) for imbalanced data:\n","  Fold 1 train class distribution: [72  8]\n","  Fold 1 test class distribution: [18  2]\n","  Fold 1: Accuracy = 0.9000\n","  Fold 2 train class distribution: [72  8]\n","  Fold 2 test class distribution: [18  2]\n","  Fold 2: Accuracy = 0.9000\n","  Fold 3 train class distribution: [72  8]\n","  Fold 3 test class distribution: [18  2]\n","  Fold 3: Accuracy = 0.9000\n","  Fold 4 train class distribution: [72  8]\n","  Fold 4 test class distribution: [18  2]\n","  Fold 4: Accuracy = 0.9000\n","  Fold 5 train class distribution: [72  8]\n","  Fold 5 test class distribution: [18  2]\n","  Fold 5: Accuracy = 0.9000\n","\n","Average Stratified Accuracy: 0.9000\n"]}]},{"cell_type":"markdown","metadata":{"id":"ded3f206"},"source":["### **4. Time Series Split**\n","\n","For time-dependent data (time series), standard random splits or K-Fold Cross-Validation are not appropriate because they would mix future data with past data, leading to data leakage and an overly optimistic performance estimate. Time series splits maintain the temporal order of the data."]},{"cell_type":"markdown","metadata":{"id":"a041b8b2"},"source":["**When to Use:**\n","*   Exclusively for time series data where the order of observations matters (e.g., stock prices, sensor readings, weather data).\n","\n","**Pros:**\n","*   Preserves the temporal order, preventing data leakage from future into past.\n","*   Provides a more realistic evaluation of a model's ability to forecast future events.\n","\n","**Cons:**\n","*   The training sets grow larger with each split, while the test sets remain constant (or can be fixed in size).\n","*   Can be less stable if there are significant temporal shifts in the data that are not captured in early training folds.\n","*   The earliest training sets might be too small to adequately train a complex model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9ef7b49","executionInfo":{"status":"ok","timestamp":1768162837382,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anant Prakash Awasthi","userId":"00676186995527977815"}},"outputId":"36120438-04f5-4243-fc26-383a909e4f44"},"source":["from sklearn.model_selection import TimeSeriesSplit\n","import pandas as pd\n","\n","# Generate a dummy time series dataset\n","dates = pd.date_range(start='2023-01-01', periods=100, freq='D')\n","X_ts = np.arange(100).reshape(-1, 1) + np.random.rand(100, 4) # Features\n","y_ts = np.sin(np.arange(100)/10) + np.random.rand(100) * 0.1 # Target\n","\n","print(f\"Original time series dataset shape: X={X_ts.shape}, y={y_ts.shape}\")\n","\n","# Initialize TimeSeriesSplit\n","tscv = TimeSeriesSplit(n_splits=5)\n","\n","print(\"\\nPerforming Time Series Split (n_splits=5):\")\n","for fold, (train_index, test_index) in enumerate(tscv.split(X_ts)):\n","    X_train, X_test = X_ts[train_index], X_ts[test_index]\n","    y_train, y_test = y_ts[train_index], y_ts[test_index]\n","\n","    print(f\"  Fold {fold+1}:\")\n","    print(f\"    Train dates: {dates[train_index.min()]} to {dates[train_index.max()]}\")\n","    print(f\"    Test dates: {dates[test_index.min()]} to {dates[test_index.max()]}\")\n","    print(f\"    Train size: {len(train_index)}, Test size: {len(test_index)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original time series dataset shape: X=(100, 4), y=(100,)\n","\n","Performing Time Series Split (n_splits=5):\n","  Fold 1:\n","    Train dates: 2023-01-01 00:00:00 to 2023-01-20 00:00:00\n","    Test dates: 2023-01-21 00:00:00 to 2023-02-05 00:00:00\n","    Train size: 20, Test size: 16\n","  Fold 2:\n","    Train dates: 2023-01-01 00:00:00 to 2023-02-05 00:00:00\n","    Test dates: 2023-02-06 00:00:00 to 2023-02-21 00:00:00\n","    Train size: 36, Test size: 16\n","  Fold 3:\n","    Train dates: 2023-01-01 00:00:00 to 2023-02-21 00:00:00\n","    Test dates: 2023-02-22 00:00:00 to 2023-03-09 00:00:00\n","    Train size: 52, Test size: 16\n","  Fold 4:\n","    Train dates: 2023-01-01 00:00:00 to 2023-03-09 00:00:00\n","    Test dates: 2023-03-10 00:00:00 to 2023-03-25 00:00:00\n","    Train size: 68, Test size: 16\n","  Fold 5:\n","    Train dates: 2023-01-01 00:00:00 to 2023-03-25 00:00:00\n","    Test dates: 2023-03-26 00:00:00 to 2023-04-10 00:00:00\n","    Train size: 84, Test size: 16\n"]}]},{"cell_type":"markdown","metadata":{"id":"3297b91a"},"source":["### **5. Group K-Fold Cross-Validation**\n","\n","Group K-Fold Cross-Validation is used when your data has inherent groups where samples within a group are related (e.g., multiple medical records from the same patient, or observations from the same geographic region). It ensures that all samples from a single group appear together in either the training set or the test set, but never in both. This prevents data leakage that could occur if samples from the same group are present in both sets."]},{"cell_type":"markdown","metadata":{"id":"9410d454"},"source":["**When to Use:**\n","*   When data points are not independent and identically distributed (i.i.d.) due to underlying groups.\n","*   To avoid data leakage when a model might learn specific characteristics of a group if its members are split across training and test sets (e.g., patient-specific features).\n","\n","**Pros:**\n","*   Prevents data leakage due to group dependencies.\n","*   Provides a more realistic evaluation of model performance on entirely unseen groups.\n","\n","**Cons:**\n","*   Requires an explicit 'group' variable in the dataset.\n","*   Can lead to imbalanced fold sizes if group sizes vary significantly.\n","*   Computationally more expensive than a simple train/test split."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10f22d4f","executionInfo":{"status":"ok","timestamp":1768162838174,"user_tz":-330,"elapsed":255,"user":{"displayName":"Anant Prakash Awasthi","userId":"00676186995527977815"}},"outputId":"aee93261-24c6-44fb-ff0d-2cb312231990"},"source":["from sklearn.model_selection import GroupKFold\n","\n","# Generate a dummy dataset with groups\n","X_group = np.random.rand(100, 5)\n","y_group = np.random.randint(0, 2, 100)\n","# Assume 10 distinct groups, with 10 samples each\n","groups = np.repeat(np.arange(10), 10)\n","np.random.shuffle(groups) # Shuffle to make sure groups are not ordered\n","\n","print(f\"Original grouped dataset shape: X={X_group.shape}, y={y_group.shape}, groups={groups.shape}\")\n","\n","# Initialize GroupKFold\n","gkf = GroupKFold(n_splits=5)\n","\n","print(\"\\nPerforming Group K-Fold Cross-Validation (n_splits=5):\")\n","for fold, (train_index, test_index) in enumerate(gkf.split(X_group, y_group, groups)):\n","    X_train, X_test = X_group[train_index], X_group[test_index]\n","    y_train, y_test = y_group[train_index], y_group[test_index]\n","    groups_train, groups_test = groups[train_index], groups[test_index]\n","\n","    print(f\"  Fold {fold+1}:\")\n","    print(f\"    Train size: {len(train_index)}, Test size: {len(test_index)}\")\n","    print(f\"    Train groups: {np.unique(groups_train)}\")\n","    print(f\"    Test groups: {np.unique(groups_test)}\")\n","    # Verify no group overlaps between train and test\n","    assert len(np.intersect1d(np.unique(groups_train), np.unique(groups_test))) == 0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original grouped dataset shape: X=(100, 5), y=(100,), groups=(100,)\n","\n","Performing Group K-Fold Cross-Validation (n_splits=5):\n","  Fold 1:\n","    Train size: 80, Test size: 20\n","    Train groups: [0 1 2 3 5 6 7 8]\n","    Test groups: [4 9]\n","  Fold 2:\n","    Train size: 80, Test size: 20\n","    Train groups: [0 1 2 4 5 6 7 9]\n","    Test groups: [3 8]\n","  Fold 3:\n","    Train size: 80, Test size: 20\n","    Train groups: [0 1 3 4 5 6 8 9]\n","    Test groups: [2 7]\n","  Fold 4:\n","    Train size: 80, Test size: 20\n","    Train groups: [0 2 3 4 5 7 8 9]\n","    Test groups: [1 6]\n","  Fold 5:\n","    Train size: 80, Test size: 20\n","    Train groups: [1 2 3 4 6 7 8 9]\n","    Test groups: [0 5]\n"]}]},{"cell_type":"markdown","metadata":{"id":"e2932ac9"},"source":["### **Conclusion**\n","\n","Choosing the right data splitting strategy is crucial for obtaining reliable model evaluation and building robust machine learning models. The decision depends on the nature of your data (e.g., imbalanced classes, time series, grouped data) and the computational resources available. Always consider the potential for data leakage and strive for a validation strategy that closely mimics how your model will perform in a real-world scenario."]}]}